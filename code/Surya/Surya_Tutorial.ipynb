{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Surya OCR Text Extraction"
      ],
      "metadata": {
        "id": "beBpqHA-qV2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Surya?"
      ],
      "metadata": {
        "id": "44zynK-0qY86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surya is a tool for performing Optical Character Recognition (OCR) on images or documents with text. It designed specifically with structured documents in mind, and performs well across dozens of languages. Its results are very impressive when compared to other openly available OCR tools, including Google's much-utilized Tesseract.\n",
        "\n",
        "Although Surya's output resembles that of a conventional OCR engine in the sense that it will reproduce text strings from an input image, it is based on a machine learning model called [DONUT](https://arxiv.org/abs/2111.15664) (Document Understanding Transformer), which was released in 2021. Unlike traditional OCR engines, the DONUT architecture utilises a Transformer-based model which simultaneously analyses a document's layout, structure and content, without performing OCR as a separate step.\n",
        "\n"
      ],
      "metadata": {
        "id": "G_HY0LCOy7Xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you begin"
      ],
      "metadata": {
        "id": "HxtDhSsb_OpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start processing your images or documents, it is a good idea to check that they are in the correct format. If you are using images, check that the text is clearly visible, and that any background has been cropped out of the picture.\n"
      ],
      "metadata": {
        "id": "O_m9DPaC_RO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you simply want to test the code**, the cells below will pull a volume of the [Journal of Fabrics and Textile Industries](https://archive.org/details/journaloffabrics03unse/page/n7/mode/2up) from 1882, and will save two pages as images in a folder."
      ],
      "metadata": {
        "id": "53DcnH4qvOn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 pdf2image"
      ],
      "metadata": {
        "id": "jZlCLdl0v6pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "id": "wJs__PchwUU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "IzBasrQiufBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://dn790000.ca.archive.org/0/items/journaloffabrics03unse/journaloffabrics03unse.pdf', stream=True)\n",
        "\n",
        "save_path = \"/content/journaloffabrics03unse.pdf\"\n",
        "\n",
        "\n",
        "with open(save_path, 'wb') as file:\n",
        "    for chunk in response.iter_content(chunk_size=1024):\n",
        "        file.write(chunk)\n",
        "\n",
        "print(f\"PDF successfully downloaded and saved to {save_path}\")"
      ],
      "metadata": {
        "id": "piYQ-Lmut7TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def extract_pages_as_images(pdf_path, pages, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    images = convert_from_path(pdf_path, first_page=min(pages), last_page=max(pages))\n",
        "\n",
        "    for page_num, image in zip(range(min(pages), max(pages) + 1), images):\n",
        "        if page_num in pages:\n",
        "            image_path = os.path.join(output_dir, f\"page_{page_num}.png\")\n",
        "            image.save(image_path, \"PNG\")\n",
        "            print(f\"Saved page {page_num} as {image_path}\")\n",
        "\n",
        "pdf_path = \"/content/journaloffabrics03unse.pdf\"  # Path to the PDF file\n",
        "pages = [12, 13]  # Pages to extract (1-based index)\n",
        "output_dir = \"/content/surya_input\"  # Directory to save images\n",
        "\n",
        "extract_pages_as_images(pdf_path, pages, output_dir)"
      ],
      "metadata": {
        "id": "V3gYW_QAvmBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ],
      "metadata": {
        "id": "iPE9ebnlqcHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the most of out Surya's capabilities, run it through a hosted runtime on Google Colab. You can choose a hosted runtime by navigating to the top right-hand corner of the notebook and clicking on the triangle to the right of the RAM/Disk indictator (see image below). Make sure that you choose a GPU runtime when selecting from the options available.\n",
        "\n",
        "While it is possible to run Surya on a CPU, the processing time is likely to be long. If you own a recent Macbook computer, you may also be able to run it locally on your machine, depending on your specifications. For example, a test using four images as input on an M1 Macbook Air took 32 minutes. Running the same process on an L4 GPU hosted runtime took under a minute. To find out more, please refer to the [Surya documentation](https://github.com/VikParuchuri/surya).\n",
        "\n",
        "***Warning***: while Colab has a number of free options for hosted runtimes, processing large OCR batches will require that you to purchase compute units from Google. Depending on your system's specifications, you may also be able to run Surya locally."
      ],
      "metadata": {
        "id": "VTBtqJvcqhYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img width=350 src='https://drive.google.com/uc?id=1-1kVQjE2Zco6kG6NLVZsg0L5vzqm3e5i'/>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "SXg9KlV7sttZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Surya"
      ],
      "metadata": {
        "id": "-gSh9JC2BQO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step in setting up Surya is to install the package via pip. Run the following cell to do this. Once Surya has successfully installed, you will see the following warning:\n",
        "\n",
        "**WARNING: The following packages were previously imported in this runtime: [PIL]\n",
        "You must restart the runtime in order to use newly installed versions.**\n",
        "\n",
        "You will be prompted by Colab to restart your session and delete the runtime. Click on 'restart session' and scroll down to the next cell."
      ],
      "metadata": {
        "id": "8geMZKopu1Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surya-ocr"
      ],
      "metadata": {
        "id": "HJu-l0nbsuwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload your documents"
      ],
      "metadata": {
        "id": "8Kih8kBPxFOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surya will take as input PDFs, images, or folders containing collections of either. For the purposes of this notebook, you will want to navigate to the left-hand pane in Colab, and select the 'Files' icon. A tab will open up. Right-click to show the available options, and select 'New folder'. Let's rename this folder 'surya_input'.\n",
        "\n",
        "**If you extracted the example pages from archive.org above, you don't need to do this. The images will be saved in a folder called 'surya_input'**"
      ],
      "metadata": {
        "id": "tsmj6_uVBXBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img width=350 src='https://drive.google.com/uc?id=1D9INA-PvN-ZNpxWieiaouqq1fdDDaAGe'/>\n",
        "</figure>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NHv4YXgsBb3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now drag your individual files into this folder ready for processing."
      ],
      "metadata": {
        "id": "ZxYUwKJ8CnfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Surya in the CLI"
      ],
      "metadata": {
        "id": "V7Z2oLMdCwfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While you can use Surya in Python for greater flexibility, we have found that running via the CLI is by far the easiest way to run the tool. To perform OCR on the files uploaded to our 'surya_input' folder, run the following code:"
      ],
      "metadata": {
        "id": "tZ6gcNqlC1jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!surya_ocr '/content/surya_input' --langs en --results_dir '/content/surya_output'"
      ],
      "metadata": {
        "id": "5ydjEVWeCvVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will output a json file for each of your documents/images with the following fields for each text line detected:\n",
        "\n",
        "*   text\n",
        "*   confidence\n",
        "* polygon\n",
        "* bbox\n",
        "\n"
      ],
      "metadata": {
        "id": "UYOOYdHRD6MC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will save a json file with the name 'results.json'.\n",
        "\n",
        "You can now download the json file for use in other applications."
      ],
      "metadata": {
        "id": "hFZ4eeVSJXnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract text fields as .txt files"
      ],
      "metadata": {
        "id": "WQa2gDVhJxm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to end up with .txt files corresponding to each json file created, you can use the following code. [Generated by Chat GPT]\n",
        "\n",
        "Before you execute the code, create a new folder with the name 'text_files'."
      ],
      "metadata": {
        "id": "oKKvYgrcJ1gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def save_text_lines_to_individual_files(json_directory, output_directory):\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Iterate over all JSON files in the given directory\n",
        "    for json_file_name in os.listdir(json_directory):\n",
        "        if json_file_name.endswith('.json'):\n",
        "            json_file_path = os.path.join(json_directory, json_file_name)\n",
        "\n",
        "            # Load the JSON data from the file\n",
        "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "            # Create a corresponding .txt file name\n",
        "            txt_file_name = f\"{os.path.splitext(json_file_name)[0]}.txt\"\n",
        "            txt_file_path = os.path.join(output_directory, txt_file_name)\n",
        "\n",
        "            # Open the text file for writing\n",
        "            with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
        "                # Iterate through the JSON structure to extract and print text lines\n",
        "                for image_name, pages in data.items():\n",
        "                    for page in pages:\n",
        "                        text_lines = page.get(\"text_lines\", [])\n",
        "                        for text_line in text_lines:\n",
        "                            text = text_line.get('text', '')\n",
        "                            txt_file.write(text + '\\n')\n",
        "\n",
        "json_directory = '/content/surya_output/surya_input'  # Replace with the path to your directory containing JSON files\n",
        "output_directory = '/content/text_files'  # Replace with the desired output directory for text files\n",
        "save_text_lines_to_individual_files(json_directory, output_directory)\n"
      ],
      "metadata": {
        "id": "fz4voh-LEAzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!surya_ocr '/content/surya_input' --langs en --results_dir '/content/surya_output'"
      ],
      "metadata": {
        "id": "ourl783CLJma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Layout Detection"
      ],
      "metadata": {
        "id": "q3wooj4SweOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from surya.detection import batch_text_detection\n",
        "from surya.layout import batch_layout_detection\n",
        "from surya.model.detection.model import load_model as load_det_model, load_processor as load_det_processor\n",
        "from surya.model.layout.model import load_model as load_layout_model\n",
        "from surya.model.layout.processor import load_processor as load_layout_processor\n",
        "\n",
        "IMAGE_PATH = '/content/PART II 5.jpeg'\n",
        "\n",
        "image = Image.open(IMAGE_PATH)\n",
        "model = load_layout_model()\n",
        "processor = load_layout_processor()\n",
        "det_model = load_det_model()\n",
        "det_processor = load_det_processor()\n",
        "\n",
        "# layout_predictions is a list of dicts, one per image\n",
        "line_predictions = batch_text_detection([image], det_model, det_processor)\n",
        "layout_predictions = batch_layout_detection([image], model, processor, line_predictions)"
      ],
      "metadata": {
        "id": "bzv9iYIywhXq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}